{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: p < 0.01, |logFC| > 10, using median\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import anndata as ad\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration constants\n",
    "PVAL_THRESHOLD = 0.01\n",
    "LOGFC_THRESHOLD = 10\n",
    "\n",
    "print(f\"Configuration: p < {PVAL_THRESHOLD}, |logFC| > {LOGFC_THRESHOLD}, using median\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA MANAGEMENT ===\n",
      "üìÅ Found 1 existing data file(s) in ../data:\n",
      "   ‚Ä¢ test_data.h5ad (124,918,273 bytes, 119.1 MB)\n",
      "Data directory: /Users/jmsung/projects/bio-ml/diff_exp/data\n",
      "‚úÖ Data file already exists: /Users/jmsung/projects/bio-ml/diff_exp/data/test_data.h5ad\n",
      "   File size: 124,918,273 bytes (119.1 MB)\n",
      "   Skipping download. Use force_download=True to re-download.\n"
     ]
    }
   ],
   "source": [
    "def parse_s3_uri(s3_uri):\n",
    "    \"\"\"Parse S3 URI to extract bucket and key\"\"\"\n",
    "    if not s3_uri.startswith('s3://'):\n",
    "        raise ValueError(\"Invalid S3 URI. Must start with 's3://'\")\n",
    "    \n",
    "    # Remove 's3://' prefix\n",
    "    path = s3_uri[5:]\n",
    "    \n",
    "    # Split into bucket and key\n",
    "    parts = path.split('/', 1)\n",
    "    bucket = parts[0]\n",
    "    key = parts[1] if len(parts) > 1 else ''\n",
    "    \n",
    "    return bucket, key\n",
    "\n",
    "def download_from_s3(bucket, key, local_path, aws_access_key_id, aws_secret_access_key):\n",
    "    \"\"\"Download file from S3 using provided credentials\"\"\"\n",
    "    # Create a session using provided credentials\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "    )\n",
    "\n",
    "    s3 = session.client('s3')\n",
    "    try:\n",
    "        s3.download_file(bucket, key, local_path)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        print(f\"Error downloading from S3: {e}\")\n",
    "        return False\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load configuration from .env file in parent directory\"\"\"\n",
    "    load_dotenv('../.env')\n",
    "    \n",
    "    config = {\n",
    "        'aws_access_key_id': os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "        'aws_secret_access_key': os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "        'data_uri': os.getenv('DATA_URI')\n",
    "    }\n",
    "    \n",
    "    # Validate that all required variables are present\n",
    "    missing_vars = [key for key, value in config.items() if not value]\n",
    "    if missing_vars:\n",
    "        raise ValueError(f\"Missing required environment variables: {missing_vars}\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "def check_existing_data(data_dir):\n",
    "    \"\"\"Check what data files already exist in the data directory\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"üìÅ Data directory does not exist: {data_dir}\")\n",
    "        return []\n",
    "    \n",
    "    files = [f for f in os.listdir(data_dir) if f.endswith('.h5ad')]\n",
    "    \n",
    "    if files:\n",
    "        print(f\"üìÅ Found {len(files)} existing data file(s) in {data_dir}:\")\n",
    "        for file in files:\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"   ‚Ä¢ {file} ({file_size:,} bytes, {file_size/1024/1024:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"üìÅ No .h5ad files found in {data_dir}\")\n",
    "    \n",
    "    return files\n",
    "\n",
    "def download_data(data_dir, force_download=False):\n",
    "    \"\"\"Main function to orchestrate the data download\"\"\"\n",
    "    # Load configuration\n",
    "    config = load_config()\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    print(f\"Data directory: {os.path.abspath(data_dir)}\")\n",
    "    \n",
    "    # Parse the DATA_URI and download the file\n",
    "    bucket, key = parse_s3_uri(config['data_uri'])\n",
    "    \n",
    "    # Extract filename from S3 key or use default\n",
    "    filename = os.path.basename(key) if key else 'test_data.h5ad'\n",
    "    if not filename.endswith('.h5ad'):\n",
    "        filename = 'test_data.h5ad'\n",
    "    \n",
    "    # Full path to save the file\n",
    "    local_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(local_path) and not force_download:\n",
    "        file_size = os.path.getsize(local_path)\n",
    "        print(f\"‚úÖ Data file already exists: {os.path.abspath(local_path)}\")\n",
    "        print(f\"   File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n",
    "        print(\"   Skipping download. Use force_download=True to re-download.\")\n",
    "        return True, local_path\n",
    "    \n",
    "    # Download the file\n",
    "    print(f\"Downloading data from S3...\")\n",
    "    success = download_from_s3(\n",
    "        bucket=bucket,\n",
    "        key=key,\n",
    "        local_path=local_path,\n",
    "        aws_access_key_id=config['aws_access_key_id'],\n",
    "        aws_secret_access_key=config['aws_secret_access_key']\n",
    "    )\n",
    "    \n",
    "    if success:\n",
    "        file_size = os.path.getsize(local_path)\n",
    "        print(f\"‚úÖ Data download completed successfully!\")\n",
    "        print(f\"   File saved to: {os.path.abspath(local_path)}\")\n",
    "        print(f\"   File size: {file_size:,} bytes ({file_size/1024/1024:.1f} MB)\")\n",
    "    else:\n",
    "        print(\"Data download failed!\")\n",
    "    \n",
    "    return success, local_path if success else None\n",
    "\n",
    "# Execute the download\n",
    "data_dir = '../data'\n",
    "print(\"=== DATA MANAGEMENT ===\")\n",
    "\n",
    "# Check existing data files first\n",
    "existing_files = check_existing_data(data_dir)\n",
    "\n",
    "# Download data (will skip if already exists)\n",
    "success, data_file = download_data(data_dir, force_download=False)\n",
    "\n",
    "# Optional: Force re-download if needed\n",
    "# success, data_file = download_data(data_dir, force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data with shape: (5025, 61198)\n",
      "Number of genes (variables): 61198\n",
      "Number of cells (observations): 5025\n",
      "\n",
      "==================================================\n",
      "DATA EXPLORATION\n",
      "==================================================\n",
      "\n",
      "1. Data Matrix Information:\n",
      "   - Data type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "   - Matrix shape: (5025, 61198)\n",
      "   - Data dtype: float32\n",
      "\n",
      "2. Gene (Variable) Information:\n",
      "   - First 10 gene names: ['DDX11L1', 'WASH7P', 'MIR6859-1', 'MIR1302-2HG', 'MIR1302-2', 'FAM138A', 'OR4G4P', 'OR4G11P', 'OR4F5', 'LOC100996442']\n",
      "   - Gene annotation columns: []\n",
      "\n",
      "3. Cell (Observation) Information:\n",
      "   - Cell annotation columns: ['cell_id', 'group']\n",
      "   - Cell annotations preview:\n",
      "                 cell_id      group\n",
      "7212  AAACCCAAGCCATTCA-1  treatment\n",
      "7213  AAACCCAAGTGACACG-1    control\n",
      "7214  AAACCCACAGCTGTCG-1    control\n",
      "7215  AAACCCAGTATCTTCT-1    control\n",
      "7216  AAACCCAGTCGAATGG-1    control\n",
      "\n",
      "4. Condition/Treatment Analysis:\n",
      "   - No 'condition' or 'treatment' column found\n",
      "   - Available columns for grouping:\n",
      "     * cell_id: ['AAACCCAAGCCATTCA-1' 'AAACCCAAGTGACACG-1' 'AAACCCACAGCTGTCG-1'\n",
      " 'AAACCCAGTATCTTCT-1' 'AAACCCAGTCGAATGG-1']\n",
      "     * group: ['treatment', 'control']\n",
      "Categories (2, object): ['control', 'treatment']\n",
      "\n",
      "5. Expression Data Summary:\n",
      "   - Matrix type: Sparse\n",
      "   - Sample values (first 5x5):\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "   - Expression range: 0.000 to 2218.000\n",
      "   - Mean expression: 0.144\n",
      "\n",
      "6. Additional Data Layers:\n",
      "   - No additional layers found\n",
      "   - No observation matrices found\n",
      "   - No variable matrices found\n"
     ]
    }
   ],
   "source": [
    "# Load and explore the h5ad file\n",
    "if success and data_file:\n",
    "    print(\"Loading data...\")\n",
    "    adata = ad.read_h5ad(data_file)\n",
    "    \n",
    "    print(f\"Loaded data with shape: {adata.shape}\")\n",
    "    print(f\"Number of genes (variables): {adata.n_vars}\")\n",
    "    print(f\"Number of cells (observations): {adata.n_obs}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA EXPLORATION\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Basic data structure\n",
    "    print(\"\\n1. Data Matrix Information:\")\n",
    "    print(f\"   - Data type: {type(adata.X)}\")\n",
    "    print(f\"   - Matrix shape: {adata.X.shape}\")\n",
    "    print(f\"   - Data dtype: {adata.X.dtype}\")\n",
    "\n",
    "    # Gene information\n",
    "    print(\"\\n2. Gene (Variable) Information:\")\n",
    "    print(f\"   - First 10 gene names: {adata.var_names[:10].tolist()}\")\n",
    "    print(f\"   - Gene annotation columns: {adata.var.columns.tolist()}\")\n",
    "    if not adata.var.empty:\n",
    "        print(\"   - Gene annotations preview:\")\n",
    "        print(adata.var.head())\n",
    "\n",
    "    # Cell information  \n",
    "    print(\"\\n3. Cell (Observation) Information:\")\n",
    "    print(f\"   - Cell annotation columns: {adata.obs.columns.tolist()}\")\n",
    "    print(\"   - Cell annotations preview:\")\n",
    "    print(adata.obs.head())\n",
    "\n",
    "    # Check for condition/treatment information\n",
    "    print(\"\\n4. Condition/Treatment Analysis:\")\n",
    "    if 'condition' in adata.obs.columns:\n",
    "        print(f\"   - Found 'condition' column!\")\n",
    "        print(f\"   - Conditions: {adata.obs['condition'].value_counts().to_dict()}\")\n",
    "    elif 'treatment' in adata.obs.columns:\n",
    "        print(f\"   - Found 'treatment' column!\")\n",
    "        print(f\"   - Treatments: {adata.obs['treatment'].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(\"   - No 'condition' or 'treatment' column found\")\n",
    "        print(\"   - Available columns for grouping:\")\n",
    "        for col in adata.obs.columns:\n",
    "            if adata.obs[col].dtype == 'object' or adata.obs[col].dtype.name == 'category':\n",
    "                print(f\"     * {col}: {adata.obs[col].unique()[:5]}\")\n",
    "\n",
    "    # Expression data summary\n",
    "    print(\"\\n5. Expression Data Summary:\")\n",
    "    if hasattr(adata.X, 'toarray'):\n",
    "        # Sparse matrix\n",
    "        sample_data = adata.X[:100, :100].toarray()\n",
    "        print(f\"   - Matrix type: Sparse\")\n",
    "        print(f\"   - Sample values (first 5x5):\")\n",
    "        print(sample_data[:5, :5])\n",
    "    else:\n",
    "        # Dense matrix\n",
    "        print(f\"   - Matrix type: Dense\")\n",
    "        print(f\"   - Sample values (first 5x5):\")\n",
    "        print(adata.X[:5, :5])\n",
    "\n",
    "    print(f\"   - Expression range: {adata.X.min():.3f} to {adata.X.max():.3f}\")\n",
    "    print(f\"   - Mean expression: {adata.X.mean():.3f}\")\n",
    "\n",
    "    # Check for other data layers\n",
    "    print(\"\\n6. Additional Data Layers:\")\n",
    "    if adata.layers:\n",
    "        print(f\"   - Available layers: {list(adata.layers.keys())}\")\n",
    "    else:\n",
    "        print(\"   - No additional layers found\")\n",
    "\n",
    "    if adata.obsm:\n",
    "        print(f\"   - Observation matrices (obsm): {list(adata.obsm.keys())}\")\n",
    "    else:\n",
    "        print(\"   - No observation matrices found\")\n",
    "\n",
    "    if adata.varm:\n",
    "        print(f\"   - Variable matrices (varm): {list(adata.varm.keys())}\")\n",
    "    else:\n",
    "        print(\"   - No variable matrices found\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot load data: Download failed or file path not available\")\n",
    "    print(\"Please run the download cell first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(100, 100), dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X[:100, :100].toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outlier detection function: symmetric percentile removal\n",
      "For 95% threshold: removes bottom 2.5% and top 2.5% of values\n",
      "For 99% threshold: removes bottom 0.5% and top 0.5% of values\n"
     ]
    }
   ],
   "source": [
    "# Updated outlier detection function for symmetric percentile removal\n",
    "def detect_outliers_percentile(expression_data, percentile_threshold=95):\n",
    "    \"\"\"\n",
    "    Detect outliers using symmetric percentile-based method\n",
    "    \n",
    "    Parameters:\n",
    "    expression_data: array of expression values\n",
    "    percentile_threshold: central percentage to keep (e.g., 95 means keep middle 95%, \n",
    "                         remove bottom 2.5% and top 2.5%)\n",
    "    \n",
    "    Returns:\n",
    "    Boolean mask where True indicates outlier\n",
    "    \"\"\"\n",
    "    if len(expression_data) == 0:\n",
    "        return np.array([], dtype=bool)\n",
    "    \n",
    "    # Calculate symmetric bounds\n",
    "    # For 95%, remove bottom 2.5% and top 2.5%\n",
    "    lower_percentile = (100 - percentile_threshold) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    \n",
    "    lower_bound = np.percentile(expression_data, lower_percentile)\n",
    "    upper_bound = np.percentile(expression_data, upper_percentile)\n",
    "    \n",
    "    # Identify outliers (values below lower bound OR above upper bound)\n",
    "    outlier_mask = (expression_data < lower_bound) | (expression_data > upper_bound)\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "print(f\"Updated outlier detection function: symmetric percentile removal\")\n",
    "print(f\"For 95% threshold: removes bottom 2.5% and top 2.5% of values\")\n",
    "print(f\"For 99% threshold: removes bottom 0.5% and top 0.5% of values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outlier detection function: symmetric percentile removal\n",
      "For 95% threshold: removes bottom 2.5% and top 2.5% of values\n",
      "For 99% threshold: removes bottom 0.5% and top 0.5% of values\n"
     ]
    }
   ],
   "source": [
    "# Updated outlier detection function for symmetric percentile removal\n",
    "def detect_outliers_percentile(expression_data, percentile_threshold=95):\n",
    "    \"\"\"\n",
    "    Detect outliers using symmetric percentile-based method\n",
    "    \n",
    "    Parameters:\n",
    "    expression_data: array of expression values\n",
    "    percentile_threshold: central percentage to keep (e.g., 95 means keep middle 95%, \n",
    "                         remove bottom 2.5% and top 2.5%)\n",
    "    \n",
    "    Returns:\n",
    "    Boolean mask where True indicates outlier\n",
    "    \"\"\"\n",
    "    if len(expression_data) == 0:\n",
    "        return np.array([], dtype=bool)\n",
    "    \n",
    "    # Calculate symmetric bounds\n",
    "    # For 95%, remove bottom 2.5% and top 2.5%\n",
    "    lower_percentile = (100 - percentile_threshold) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    \n",
    "    lower_bound = np.percentile(expression_data, lower_percentile)\n",
    "    upper_bound = np.percentile(expression_data, upper_percentile)\n",
    "    \n",
    "    # Identify outliers (values below lower bound OR above upper bound)\n",
    "    outlier_mask = (expression_data < lower_bound) | (expression_data > upper_bound)\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "print(f\"Updated outlier detection function: symmetric percentile removal\")\n",
    "print(f\"For 95% threshold: removes bottom 2.5% and top 2.5% of values\")\n",
    "print(f\"For 99% threshold: removes bottom 0.5% and top 0.5% of values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outlier detection function: symmetric percentile removal\n",
      "For 95% threshold: removes bottom 2.5% and top 2.5% of values\n",
      "For 99% threshold: removes bottom 0.5% and top 0.5% of values\n"
     ]
    }
   ],
   "source": [
    "# Updated outlier detection function for symmetric percentile removal\n",
    "def detect_outliers_percentile(expression_data, percentile_threshold=95):\n",
    "    \"\"\"\n",
    "    Detect outliers using symmetric percentile-based method\n",
    "    \n",
    "    Parameters:\n",
    "    expression_data: array of expression values\n",
    "    percentile_threshold: central percentage to keep (e.g., 95 means keep middle 95%, \n",
    "                         remove bottom 2.5% and top 2.5%)\n",
    "    \n",
    "    Returns:\n",
    "    Boolean mask where True indicates outlier\n",
    "    \"\"\"\n",
    "    if len(expression_data) == 0:\n",
    "        return np.array([], dtype=bool)\n",
    "    \n",
    "    # Calculate symmetric bounds\n",
    "    # For 95%, remove bottom 2.5% and top 2.5%\n",
    "    lower_percentile = (100 - percentile_threshold) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    \n",
    "    lower_bound = np.percentile(expression_data, lower_percentile)\n",
    "    upper_bound = np.percentile(expression_data, upper_percentile)\n",
    "    \n",
    "    # Identify outliers (values below lower bound OR above upper bound)\n",
    "    outlier_mask = (expression_data < lower_bound) | (expression_data > upper_bound)\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "print(f\"Updated outlier detection function: symmetric percentile removal\")\n",
    "print(f\"For 95% threshold: removes bottom 2.5% and top 2.5% of values\")\n",
    "print(f\"For 99% threshold: removes bottom 0.5% and top 0.5% of values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated outlier detection function: symmetric percentile removal\n",
      "For 95% threshold: removes bottom 2.5% and top 2.5% of values\n",
      "For 99% threshold: removes bottom 0.5% and top 0.5% of values\n"
     ]
    }
   ],
   "source": [
    "# Updated outlier detection function for symmetric percentile removal\n",
    "def detect_outliers_percentile(expression_data, percentile_threshold=95):\n",
    "    \"\"\"\n",
    "    Detect outliers using symmetric percentile-based method\n",
    "    \n",
    "    Parameters:\n",
    "    expression_data: array of expression values\n",
    "    percentile_threshold: central percentage to keep (e.g., 95 means keep middle 95%, \n",
    "                         remove bottom 2.5% and top 2.5%)\n",
    "    \n",
    "    Returns:\n",
    "    Boolean mask where True indicates outlier\n",
    "    \"\"\"\n",
    "    if len(expression_data) == 0:\n",
    "        return np.array([], dtype=bool)\n",
    "    \n",
    "    # Calculate symmetric bounds\n",
    "    # For 95%, remove bottom 2.5% and top 2.5%\n",
    "    lower_percentile = (100 - percentile_threshold) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    \n",
    "    lower_bound = np.percentile(expression_data, lower_percentile)\n",
    "    upper_bound = np.percentile(expression_data, upper_percentile)\n",
    "    \n",
    "    # Identify outliers (values below lower bound OR above upper bound)\n",
    "    outlier_mask = (expression_data < lower_bound) | (expression_data > upper_bound)\n",
    "    \n",
    "    return outlier_mask\n",
    "\n",
    "print(f\"Updated outlier detection function: symmetric percentile removal\")\n",
    "print(f\"For 95% threshold: removes bottom 2.5% and top 2.5% of values\")\n",
    "print(f\"For 99% threshold: removes bottom 0.5% and top 0.5% of values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volcano plot function ready - will be used after running differential expression analysis\n",
      "=== RESULT DIRECTORY MANAGEMENT ===\n",
      "üóëÔ∏è  Deleted existing result directory (5 files): /Users/jmsung/projects/bio-ml/diff_exp/result\n",
      "‚ú® Created fresh result directory: /Users/jmsung/projects/bio-ml/diff_exp/result\n",
      "Result directory ready for analysis outputs\n"
     ]
    }
   ],
   "source": [
    "def create_volcano_plot(df, title=\"Volcano Plot: Treatment vs Control\", pval_threshold=PVAL_THRESHOLD, logFC_threshold=LOGFC_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Create interactive volcano plot using plotly with configurable significance thresholds\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with gene, logFC, p_val, -log10_pval columns\n",
    "    title: plot title\n",
    "    pval_threshold: p-value significance threshold (default: 0.01)\n",
    "    logFC_threshold: log2 fold change threshold (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "    plotly figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create significance categories\n",
    "    df = df.copy()\n",
    "    df['significance'] = 'Not Significant'\n",
    "    \n",
    "    # Significant genes (p < threshold and |logFC| > threshold)\n",
    "    significant_mask = (df['p_val'] < pval_threshold) & (df['abs_logFC'] > logFC_threshold)\n",
    "    df.loc[significant_mask, 'significance'] = 'Significant'\n",
    "    \n",
    "    # Upregulated (logFC > threshold, p < threshold)\n",
    "    upregulated_mask = (df['p_val'] < pval_threshold) & (df['logFC'] > logFC_threshold)\n",
    "    df.loc[upregulated_mask, 'significance'] = 'Upregulated'\n",
    "    \n",
    "    # Downregulated (logFC < -threshold, p < threshold)\n",
    "    downregulated_mask = (df['p_val'] < pval_threshold) & (df['logFC'] < -logFC_threshold)\n",
    "    df.loc[downregulated_mask, 'significance'] = 'Downregulated'\n",
    "    \n",
    "    # Color mapping\n",
    "    color_map = {\n",
    "        'Not Significant': 'lightgray',\n",
    "        'Significant': 'orange', \n",
    "        'Upregulated': 'red',\n",
    "        'Downregulated': 'blue'\n",
    "    }\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x='logFC',\n",
    "        y='-log10_pval',\n",
    "        color='significance',\n",
    "        color_discrete_map=color_map,\n",
    "        hover_data=['gene', 'p_val'],\n",
    "        title=f\"{title}<br><sub>Thresholds: p < {pval_threshold}, |log2FC| > {logFC_threshold}</sub>\",\n",
    "        labels={\n",
    "            'logFC': 'Log2 Fold Change (Treatment vs Control)',\n",
    "            '-log10_pval': '-Log10(P-value)',\n",
    "            'significance': 'Significance'\n",
    "        },\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Add significance threshold lines\n",
    "    fig.add_hline(y=-np.log10(pval_threshold), line_dash=\"dash\", line_color=\"black\", \n",
    "                  annotation_text=f\"p-value = {pval_threshold}\")\n",
    "    fig.add_vline(x=logFC_threshold, line_dash=\"dash\", line_color=\"black\", \n",
    "                  annotation_text=f\"log2FC = {logFC_threshold}\")\n",
    "    fig.add_vline(x=-logFC_threshold, line_dash=\"dash\", line_color=\"black\", \n",
    "                  annotation_text=f\"log2FC = -{logFC_threshold}\")\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        showlegend=True,\n",
    "        title_x=0.5,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    # Count genes in each category\n",
    "    counts = df['significance'].value_counts()\n",
    "    print(f\"üìä Gene Categories (p < {pval_threshold}, |log2FC| > {logFC_threshold}):\")\n",
    "    for category, count in counts.items():\n",
    "        print(f\"  {category}: {count:,}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Volcano plot function will be used after running the analysis\n",
    "print(\"Volcano plot function ready - will be used after running differential expression analysis\")\n",
    "\n",
    "def create_result_dir(result_dir, backup_old=False):\n",
    "    \"\"\"\n",
    "    Delete existing result directory and create a fresh one\n",
    "    \n",
    "    Parameters:\n",
    "    result_dir: path to result directory\n",
    "    backup_old: if True, rename old directory instead of deleting\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle existing result directory\n",
    "    if os.path.exists(result_dir):\n",
    "        if backup_old:\n",
    "            # Create backup with timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            backup_dir = f\"{result_dir}_backup_{timestamp}\"\n",
    "            shutil.move(result_dir, backup_dir)\n",
    "            print(f\"üì¶ Backed up existing results to: {os.path.abspath(backup_dir)}\")\n",
    "        else:\n",
    "            # Count existing files before deletion\n",
    "            try:\n",
    "                existing_files = len([f for f in os.listdir(result_dir) if os.path.isfile(os.path.join(result_dir, f))])\n",
    "                shutil.rmtree(result_dir)\n",
    "                print(f\"üóëÔ∏è  Deleted existing result directory ({existing_files} files): {os.path.abspath(result_dir)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Could not delete result directory: {e}\")\n",
    "    else:\n",
    "        print(f\"üìÅ No existing result directory found\")\n",
    "    \n",
    "    # Create fresh result directory\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    print(f\"‚ú® Created fresh result directory: {os.path.abspath(result_dir)}\")\n",
    "    \n",
    "    return result_dir\n",
    "\n",
    "# Create clean result directory  \n",
    "result_dir = '../result'\n",
    "print(\"=== RESULT DIRECTORY MANAGEMENT ===\")\n",
    "\n",
    "# Clean start: delete old results and create fresh directory\n",
    "create_result_dir(result_dir, backup_old=False)\n",
    "\n",
    "# Alternative: backup old results instead of deleting\n",
    "# create_result_dir(result_dir, backup_old=True)\n",
    "\n",
    "# Plot will be saved after analysis is run\n",
    "print(\"Result directory ready for analysis outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant genes identification function ready\n"
     ]
    }
   ],
   "source": [
    "# Identify significantly differently expressed genes and create rankings\n",
    "\n",
    "def identify_significant_genes(df, pval_threshold=PVAL_THRESHOLD, logFC_threshold=LOGFC_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Identify and rank significantly differently expressed genes\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with differential expression results\n",
    "    pval_threshold: p-value cutoff for significance\n",
    "    logFC_threshold: log fold change cutoff for significance\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with upregulated, downregulated, and all significant genes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter for significant genes\n",
    "    significant_genes = df[\n",
    "        (df['p_val'] < pval_threshold) & \n",
    "        (df['abs_logFC'] > logFC_threshold)\n",
    "    ].copy()\n",
    "    \n",
    "    # Separate upregulated and downregulated\n",
    "    upregulated = significant_genes[significant_genes['logFC'] > 0].copy()\n",
    "    downregulated = significant_genes[significant_genes['logFC'] < 0].copy()\n",
    "    \n",
    "    # Sort upregulated by logFC (descending)\n",
    "    upregulated = upregulated.sort_values('logFC', ascending=False)\n",
    "    \n",
    "    # Sort downregulated by logFC (ascending, most negative first)\n",
    "    downregulated = downregulated.sort_values('logFC', ascending=True)\n",
    "    \n",
    "    # All significant genes sorted by significance (p-value then abs_logFC)\n",
    "    all_significant = significant_genes.sort_values(['p_val', 'abs_logFC'], ascending=[True, False])\n",
    "    \n",
    "    return {\n",
    "        'all_significant': all_significant,\n",
    "        'upregulated': upregulated,\n",
    "        'downregulated': downregulated\n",
    "    }\n",
    "\n",
    "# This function will be used after running the analysis\n",
    "print(\"Significant genes identification function ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Median-based differential expression analysis function ready\n"
     ]
    }
   ],
   "source": [
    "# Simplified differential expression analysis using median (robust to outliers)\n",
    "def calculate_differential_expression(adata, group_col='group', treatment_name='treatment', control_name='control'):\n",
    "    \"\"\"\n",
    "    Calculate differential expression using median-based fold change (no outlier removal needed)\n",
    "    \n",
    "    Parameters:\n",
    "    adata: AnnData object\n",
    "    group_col: column name for grouping (default: 'group')\n",
    "    treatment_name: name of treatment group (default: 'treatment')  \n",
    "    control_name: name of control group (default: 'control')\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with columns: gene, logFC, p_val, abs_logFC, -log10_pval\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üî¨ Starting median-based differential expression analysis...\")\n",
    "    print(f\"üìä Dataset: {adata.n_obs} cells √ó {adata.n_vars} genes\")\n",
    "    print(f\"üéØ Comparison: {treatment_name} vs {control_name}\")\n",
    "    print(\"üìà Using MEDIAN for fold change calculation (naturally robust to outliers)\")\n",
    "    print(\"üö´ No outlier detection needed - simplified and faster analysis\")\n",
    "    \n",
    "    # Get group masks\n",
    "    treatment_mask = adata.obs[group_col] == treatment_name\n",
    "    control_mask = adata.obs[group_col] == control_name\n",
    "    \n",
    "    print(f\"üë• Group sizes: {treatment_name}={treatment_mask.sum()}, {control_name}={control_mask.sum()}\")\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    total_genes = adata.n_vars\n",
    "    \n",
    "    print(f\"üß¨ Processing {total_genes:,} genes...\")\n",
    "    \n",
    "    # Process each gene\n",
    "    for gene_idx in range(total_genes):\n",
    "        gene_name = adata.var_names[gene_idx]\n",
    "        \n",
    "        # Extract expression data for this gene\n",
    "        if hasattr(adata.X, 'toarray'):\n",
    "            gene_expr = adata.X[:, gene_idx].toarray().flatten()\n",
    "        else:\n",
    "            gene_expr = adata.X[:, gene_idx].flatten()\n",
    "        \n",
    "        # Split by group\n",
    "        treatment_gene_expr = gene_expr[treatment_mask]\n",
    "        control_gene_expr = gene_expr[control_mask]\n",
    "        \n",
    "        # Skip genes with insufficient data\n",
    "        if len(treatment_gene_expr) < 3 or len(control_gene_expr) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Calculate medians (robust to outliers)\n",
    "        treatment_median = np.median(treatment_gene_expr)\n",
    "        control_median = np.median(control_gene_expr)\n",
    "        \n",
    "        # Calculate log2 fold change using medians (add small epsilon to avoid log(0))\n",
    "        epsilon = 1e-6\n",
    "        log_fc = np.log2((treatment_median + epsilon) / (control_median + epsilon))\n",
    "        \n",
    "        # Perform Mann-Whitney U test (non-parametric, robust to outliers)\n",
    "        try:\n",
    "            # Use alternative='two-sided' for two-tailed test\n",
    "            u_stat, p_val = mannwhitneyu(treatment_gene_expr, control_gene_expr, alternative='two-sided')\n",
    "            \n",
    "            # Handle potential NaN/infinite p-values\n",
    "            if np.isnan(p_val) or np.isinf(p_val):\n",
    "                p_val = 1.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            # If test fails, set p-value to 1 (not significant)\n",
    "            p_val = 1.0\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'gene': gene_name,\n",
    "            'logFC': log_fc,\n",
    "            'p_val': p_val,\n",
    "            'treatment_median': treatment_median,\n",
    "            'control_median': control_median,\n",
    "            'treatment_n': len(treatment_gene_expr),\n",
    "            'control_n': len(control_gene_expr)\n",
    "        })\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (gene_idx + 1) % 5000 == 0:\n",
    "            print(f\"   Processed {gene_idx + 1:,}/{total_genes:,} genes ({(gene_idx + 1)/total_genes*100:.1f}%)\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add derived columns\n",
    "    df['abs_logFC'] = np.abs(df['logFC'])\n",
    "    df['-log10_pval'] = -np.log10(df['p_val'].clip(lower=1e-300))  # Clip to avoid log(0)\n",
    "    \n",
    "    # Sort by p-value, then by absolute log fold change\n",
    "    df = df.sort_values(['p_val', 'abs_logFC'], ascending=[True, False]).reset_index(drop=True)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nüìà Analysis Complete!\")\n",
    "    print(f\"   ‚Ä¢ Genes analyzed: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Statistical test: Mann-Whitney U (non-parametric)\")\n",
    "    print(f\"   ‚Ä¢ Fold change: Log2(median_treatment / median_control)\")\n",
    "    print(f\"   ‚Ä¢ No outlier removal needed - median is naturally robust\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Median-based differential expression analysis function ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Volcano plot function ready - uses configured constants\n"
     ]
    }
   ],
   "source": [
    "# Clean volcano plot function using configured constants\n",
    "def create_volcano_plot(df, title=\"Volcano Plot: Treatment vs Control\", \n",
    "                             pval_threshold=PVAL_THRESHOLD, logFC_threshold=LOGFC_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Create interactive volcano plot using plotly with configured default thresholds\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with gene, logFC, p_val, -log10_pval columns\n",
    "    title: plot title\n",
    "    pval_threshold: p-value significance threshold (default: PVAL_THRESHOLD)\n",
    "    logFC_threshold: log2 fold change threshold (default: LOGFC_THRESHOLD)\n",
    "    \n",
    "    Returns:\n",
    "    plotly figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create significance categories\n",
    "    df = df.copy()\n",
    "    df['significance'] = 'Not Significant'\n",
    "    \n",
    "    # Significant genes (p < threshold and |logFC| > threshold)\n",
    "    significant_mask = (df['p_val'] < pval_threshold) & (df['abs_logFC'] > logFC_threshold)\n",
    "    df.loc[significant_mask, 'significance'] = 'Significant'\n",
    "    \n",
    "    # Upregulated (logFC > threshold, p < threshold)\n",
    "    upregulated_mask = (df['p_val'] < pval_threshold) & (df['logFC'] > logFC_threshold)\n",
    "    df.loc[upregulated_mask, 'significance'] = 'Upregulated'\n",
    "    \n",
    "    # Downregulated (logFC < -threshold, p < threshold)\n",
    "    downregulated_mask = (df['p_val'] < pval_threshold) & (df['logFC'] < -logFC_threshold)\n",
    "    df.loc[downregulated_mask, 'significance'] = 'Downregulated'\n",
    "    \n",
    "    # Color mapping\n",
    "    color_map = {\n",
    "        'Not Significant': 'lightgray',\n",
    "        'Significant': 'orange', \n",
    "        'Upregulated': 'red',\n",
    "        'Downregulated': 'blue'\n",
    "    }\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x='logFC',\n",
    "        y='-log10_pval',\n",
    "        color='significance',\n",
    "        color_discrete_map=color_map,\n",
    "        hover_data=['gene', 'p_val'],\n",
    "        title=f\"{title}<br><sub>Median-based: p < {pval_threshold}, |log2FC| > {logFC_threshold}</sub>\",\n",
    "        labels={\n",
    "            'logFC': 'Log2 Fold Change (Median Treatment vs Control)',\n",
    "            '-log10_pval': '-Log10(P-value)',\n",
    "            'significance': 'Significance'\n",
    "        },\n",
    "        width=800,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    # Add significance threshold lines\n",
    "    fig.add_hline(y=-np.log10(pval_threshold), line_dash=\"dash\", line_color=\"black\", \n",
    "                  annotation_text=f\"p-value = {pval_threshold}\")\n",
    "    fig.add_vline(x=logFC_threshold, line_dash=\"dash\", line_color=\"black\", \n",
    "                  annotation_text=f\"log2FC = {logFC_threshold}\")\n",
    "    fig.add_vline(x=-logFC_threshold, line_dash=\"dash\", line_color=\"black\", \n",
    "                  annotation_text=f\"log2FC = -{logFC_threshold}\")\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        showlegend=True,\n",
    "        title_x=0.5,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    # Count genes in each category\n",
    "    counts = df['significance'].value_counts()\n",
    "    print(f\"üìä Gene Categories (median-based, p < {pval_threshold}, |log2FC| > {logFC_threshold}):\")\n",
    "    for category, count in counts.items():\n",
    "        print(f\"  {category}: {count:,}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"‚úÖ Volcano plot function ready - uses configured constants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Analysis Usage:\n",
      "\n",
      "# Step 1: Run differential expression analysis\n",
      "df = calculate_differential_expression(adata)\n",
      "\n",
      "# Step 2: Create volcano plot\n",
      "fig = create_volcano_plot(df)\n",
      "\n",
      "# Step 3: Identify significant genes\n",
      "sig_genes = identify_significant_genes(df)\n",
      "\n",
      "üìä Current settings: p < 0.01, |log2FC| > 10\n",
      "üìà Median-based fold change (no outlier detection needed)\n",
      "üß™ Mann-Whitney U test (non-parametric)\n",
      "\n",
      "üí° To change thresholds: modify constants at top and re-run\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ Analysis Usage:\")\n",
    "print()\n",
    "print(\"# Step 1: Run differential expression analysis\")\n",
    "print(\"df = calculate_differential_expression(adata)\")\n",
    "print()\n",
    "print(\"# Step 2: Create volcano plot\") \n",
    "print(\"fig = create_volcano_plot(df)\")\n",
    "print()\n",
    "print(\"# Step 3: Identify significant genes\")\n",
    "print(\"sig_genes = identify_significant_genes(df)\")\n",
    "print()\n",
    "print(f\"üìä Current settings: p < {PVAL_THRESHOLD}, |log2FC| > {LOGFC_THRESHOLD}\")\n",
    "print(\"üìà Median-based fold change (no outlier detection needed)\")\n",
    "print(\"üß™ Mann-Whitney U test (non-parametric)\")\n",
    "print()\n",
    "print(\"üí° To change thresholds: modify constants at top and re-run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export results function ready - will be used after analysis completes\n"
     ]
    }
   ],
   "source": [
    "# Export results as requested\n",
    "\n",
    "def export_results(results_df, significant_results, result_dir):\n",
    "    \"\"\"\n",
    "    Export differential expression results to CSV files\n",
    "    \n",
    "    Parameters:\n",
    "    results_df: Complete differential expression results\n",
    "    significant_results: Dictionary with significant gene results\n",
    "    result_dir: Directory to save results\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Save complete results DataFrame (gene, logFC, p_val)\n",
    "    final_results = results_df[['gene', 'logFC', 'p_val']].copy()\n",
    "    results_path = os.path.join(result_dir, 'differential_expression_results.csv')\n",
    "    final_results.to_csv(results_path, index=False)\n",
    "    print(f\"‚úÖ Complete results saved to: {results_path}\")\n",
    "    print(f\"   Contains {len(final_results):,} genes with gene, logFC, p_val columns\")\n",
    "    \n",
    "    # 2. Save top 20 significant genes\n",
    "    if len(significant_results['all_significant']) > 0:\n",
    "        top_20 = significant_results['all_significant'].head(20)[['gene', 'logFC', 'p_val']].copy()\n",
    "        top_20_path = os.path.join(result_dir, 'top_20_significant_genes.csv')\n",
    "        top_20.to_csv(top_20_path, index=False)\n",
    "        print(f\"‚úÖ Top 20 significant genes saved to: {top_20_path}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No significant genes found to export\")\n",
    "    \n",
    "    # 3. Save upregulated genes\n",
    "    if len(significant_results['upregulated']) > 0:\n",
    "        upregulated_path = os.path.join(result_dir, 'upregulated_genes.csv')\n",
    "        significant_results['upregulated'][['gene', 'logFC', 'p_val']].to_csv(upregulated_path, index=False)\n",
    "        print(f\"‚úÖ Upregulated genes saved to: {upregulated_path}\")\n",
    "    \n",
    "    # 4. Save downregulated genes  \n",
    "    if len(significant_results['downregulated']) > 0:\n",
    "        downregulated_path = os.path.join(result_dir, 'downregulated_genes.csv')\n",
    "        significant_results['downregulated'][['gene', 'logFC', 'p_val']].to_csv(downregulated_path, index=False)\n",
    "        print(f\"‚úÖ Downregulated genes saved to: {downregulated_path}\")\n",
    "    \n",
    "    # 5. Save summary statistics\n",
    "    summary_stats = {\n",
    "        'total_genes_analyzed': len(results_df),\n",
    "        'significant_genes': len(significant_results['all_significant']),\n",
    "        'upregulated_genes': len(significant_results['upregulated']),\n",
    "        'downregulated_genes': len(significant_results['downregulated']),\n",
    "        'significance_threshold_pval': 0.05,\n",
    "        'significance_threshold_logFC': 1.0\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame([summary_stats])\n",
    "    summary_path = os.path.join(result_dir, 'analysis_summary.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"‚úÖ Analysis summary saved to: {summary_path}\")\n",
    "    \n",
    "    return {\n",
    "        'results_path': results_path,\n",
    "        'top_20_path': top_20_path if len(significant_results['all_significant']) > 0 else None,\n",
    "        'summary_path': summary_path\n",
    "    }\n",
    "\n",
    "# Export results function - will be used after analysis is run\n",
    "print(\"Export results function ready - will be used after analysis completes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running complete differential expression analysis...\n",
      "\n",
      "üìä Step 1: Calculating differential expression...\n",
      "üî¨ Starting median-based differential expression analysis...\n",
      "üìä Dataset: 5025 cells √ó 61198 genes\n",
      "üéØ Comparison: treatment vs control\n",
      "üìà Using MEDIAN for fold change calculation (naturally robust to outliers)\n",
      "üö´ No outlier detection needed - simplified and faster analysis\n",
      "üë• Group sizes: treatment=2543, control=2482\n",
      "üß¨ Processing 61,198 genes...\n",
      "   Processed 5,000/61,198 genes (8.2%)\n",
      "   Processed 10,000/61,198 genes (16.3%)\n",
      "   Processed 15,000/61,198 genes (24.5%)\n",
      "   Processed 20,000/61,198 genes (32.7%)\n",
      "   Processed 25,000/61,198 genes (40.9%)\n",
      "   Processed 30,000/61,198 genes (49.0%)\n",
      "   Processed 35,000/61,198 genes (57.2%)\n",
      "   Processed 40,000/61,198 genes (65.4%)\n",
      "   Processed 45,000/61,198 genes (73.5%)\n",
      "   Processed 50,000/61,198 genes (81.7%)\n",
      "   Processed 55,000/61,198 genes (89.9%)\n",
      "   Processed 60,000/61,198 genes (98.0%)\n",
      "\n",
      "üìà Analysis Complete!\n",
      "   ‚Ä¢ Genes analyzed: 61,198\n",
      "   ‚Ä¢ Statistical test: Mann-Whitney U (non-parametric)\n",
      "   ‚Ä¢ Fold change: Log2(median_treatment / median_control)\n",
      "   ‚Ä¢ No outlier removal needed - median is naturally robust\n",
      "\n",
      "üéØ Step 2: Identifying significant genes...\n",
      "\n",
      "=== RESULTS SUMMARY ===\n",
      "Total genes analyzed: 61,198\n",
      "Significant genes: 1\n",
      "  ‚Ä¢ Upregulated: 0\n",
      "  ‚Ä¢ Downregulated: 1\n",
      "\n",
      "üìà Step 3: Creating volcano plot...\n",
      "üìä Gene Categories (median-based, p < 0.01, |log2FC| > 10):\n",
      "  Not Significant: 61,197\n",
      "  Downregulated: 1\n",
      "\n",
      "üíæ Step 4: Saving results...\n",
      "üóëÔ∏è  Deleted existing result directory (0 files): /Users/jmsung/projects/bio-ml/diff_exp/result\n",
      "‚ú® Created fresh result directory: /Users/jmsung/projects/bio-ml/diff_exp/result\n",
      "‚úÖ Volcano plot saved: ../result/volcano_plot.html\n",
      "‚úÖ Complete results saved to: ../result/differential_expression_results.csv\n",
      "   Contains 61,198 genes with gene, logFC, p_val columns\n",
      "‚úÖ Top 20 significant genes saved to: ../result/top_20_significant_genes.csv\n",
      "‚úÖ Downregulated genes saved to: ../result/downregulated_genes.csv\n",
      "‚úÖ Analysis summary saved to: ../result/analysis_summary.csv\n",
      "\n",
      "üîù TOP 10 SIGNIFICANT GENES:\n",
      "    gene     logFC   p_val\n",
      "RALGAPA1 -19.93157 0.00021\n",
      "\n",
      "‚úÖ ANALYSIS COMPLETE!\n",
      "üìÅ Results saved to: /Users/jmsung/projects/bio-ml/diff_exp/result\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# RUN COMPLETE ANALYSIS PIPELINE\n",
    "# ===============================\n",
    "\n",
    "if 'adata' in locals() and adata is not None:\n",
    "    print(\"üöÄ Running complete differential expression analysis...\")\n",
    "    \n",
    "    # Step 1: Run differential expression analysis\n",
    "    print(\"\\nüìä Step 1: Calculating differential expression...\")\n",
    "    diff_expr_results = calculate_differential_expression(adata)\n",
    "    \n",
    "    # Step 2: Identify significant genes\n",
    "    print(\"\\nüéØ Step 2: Identifying significant genes...\")\n",
    "    significant_results = identify_significant_genes(diff_expr_results)\n",
    "    \n",
    "    print(f\"\\n=== RESULTS SUMMARY ===\")\n",
    "    print(f\"Total genes analyzed: {len(diff_expr_results):,}\")\n",
    "    print(f\"Significant genes: {len(significant_results['all_significant']):,}\")\n",
    "    print(f\"  ‚Ä¢ Upregulated: {len(significant_results['upregulated']):,}\")\n",
    "    print(f\"  ‚Ä¢ Downregulated: {len(significant_results['downregulated']):,}\")\n",
    "    \n",
    "    # Step 3: Create volcano plot\n",
    "    print(\"\\nüìà Step 3: Creating volcano plot...\")\n",
    "    volcano_fig = create_volcano_plot(diff_expr_results, title=\"Differential Expression Analysis\")\n",
    "    \n",
    "    # Step 4: Create results directory and save outputs\n",
    "    print(\"\\nüíæ Step 4: Saving results...\")\n",
    "    result_dir = '../result'\n",
    "    create_result_dir(result_dir, backup_old=False)\n",
    "    \n",
    "    # Save volcano plot\n",
    "    plot_path = os.path.join(result_dir, 'volcano_plot.html')\n",
    "    volcano_fig.write_html(plot_path)\n",
    "    print(f\"‚úÖ Volcano plot saved: {plot_path}\")\n",
    "    \n",
    "    # Export results\n",
    "    export_paths = export_results(diff_expr_results, significant_results, result_dir)\n",
    "    \n",
    "    # Display top results\n",
    "    if len(significant_results['all_significant']) > 0:\n",
    "        print(f\"\\nüîù TOP 10 SIGNIFICANT GENES:\")\n",
    "        top_10 = significant_results['all_significant'].head(10)\n",
    "        print(top_10[['gene', 'logFC', 'p_val']].to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No significant genes found with current thresholds\")\n",
    "        print(f\"   Consider lowering thresholds: p < {PVAL_THRESHOLD}, |logFC| > {LOGFC_THRESHOLD}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ ANALYSIS COMPLETE!\")\n",
    "    print(f\"üìÅ Results saved to: {os.path.abspath(result_dir)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Data not loaded. Please run the data loading cells first.\")\n",
    "    print(\"   The analysis will run automatically once 'adata' is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
